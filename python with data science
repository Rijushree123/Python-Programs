import pandas as pd
import numpy as np
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score,confusion_matrix

data_income=pd.read_csv("C:\ProgramData\Microsoft\Windows\Start Menu\Programs\Anaconda3 (64-bit)\income.csv")
data=data_income.copy()
print(data.info())
data.isnull()
summary_num=data.describe()
print(summary_num)

summary_cate=data.describe(include="O")
print(summary_cate)

data["JobType"].value_counts()
data["occupation"].value_counts()

print(np.unique(data["JobType"]))
print(np.unique(data["occupation"]))


data=pd.read_csv("C:\ProgramData\Microsoft\Windows\Start Menu\Programs\Anaconda3 (64-bit)\income.csv",na_values=[" ?"])
data.isnull().sum()

missing=data[data.isnull().any(axis=1)]

data2=data.dropna(axis=0)
correlation=data2.corr()
data2.columns
gender=pd.crosstab(index=data2["gender"],columns=["count"],normalize=True)
print(gender)

gender_salstat=pd.crosstab(index=data2["gender"],columns=data2["SalStat"],margins=True,normalize='index')
print(gender_salstat)

SalStat=sns.countplot(data2['SalStat'])
sns.distplot(data2["age"],bins=10,kde=False)
sns.boxplot('SalStat','age',data=data2)
data2.groupby('SalStat')['age'].median()


#========================================LOGISTIC REGRESSION#===========================================

data2['SalStat']=data2['SalStat'].map({' less than or equal to 50,000':0,' greater than 50,000':1})
print(data2['SalStat'])

new_data=pd.get_dummies(data2,drop_first=True)
columns_list=list(new_data.columns)
print(columns_list)

features=list(set(columns_list)-set(['SalStat']))
print(features)

y=new_data['SalStat'].values
print(y)
x=new_data[features].values
print(x)

#Splitting the data into train and test
train_x,test_x,train_y,test_y=train_test_split(x,y,test_size=0.3,random_state=0)
#Make an instance of model
logistic=LogisticRegression()
#Fitting the values for x and y
logistic.fit(train_x,train_y)
logistic.coef_
logistic.intercept_

#Prediction from test data
prediction=logistic.predict(test_x)
print(prediction)

#Confusion Matrix
confusion_matrix=confusion_matrix(test_y,prediction)
print(confusion_matrix)

#Calculating the accuracy
accuracy_score=accuracy_score(test_y,prediction)
print(accuracy_score)

#printing the misclassified values from prediction
print("Misclassified Samples:%d"%(test_y!=prediction).sum())

#=====================================================================================
#===========================REMOVING INSIGNIFICANT VALUES==============================
#======================================================================================

data2['SalStat']=data2['SalStat'].map({' less than or equal to 50,000':0,' greater than 50,000':1})
print(data2['SalStat'])
cols=['gender','nativecountry','race','JobType']
new_data=data2.drop(cols,axis=1)
print(new_data)
new_data=pd.get_dummies(new_data,drop_first=True)

#Storing the column names
columns_list=list(new_data.columns)
print(columns_list)

#Separating the input names from data
features=list(set(columns_list)-set(['Salstat']))
print(features)

#storing the output value in y
y=new_data['SalStat'].values
print(y)

#Storing the values from input features
x=new_data[features].values
print(x)

#Splitting the data into train and test
train_x,test_x,train_y,test_y=train_test_split(x,y,test_size=0.3,random_state=0)
#Make an instance of model
logistic=LogisticRegression()
#Fitting the values for x and y
logistic.fit(train_x,train_y)
logistic.coef_
logistic.intercept_

#Prediction from test data
prediction=logistic.predict(test_x)
print(prediction)

#Confusion Matrix
confusion_matrix=confusion_matrix(test_y,prediction)
print(confusion_matrix)

#Calculating the accuracy
accuracy_score=accuracy_score(test_y,prediction)
print(accuracy_score)

#importing the library of KNN
from sklearn.neighbors import KNeighborsClassifier
import matplotlib.pyplot as plt

#Storing the K nearest neighbour classifier
KNN_classifier=KNeighborsClassifier(n_neighbors=5)

#Fitting the values of x and y
KNN_classifier.fit(train_x,train_y)

#predicting the test values 
prediction=KNN_classifier.predict(test_x)
print(prediction)

#Performamce metric check
confusion_matrix=confusion_matrix(test_y,prediction)
print(confusion_matrix)

#Calculating the accuracy
accuracy_score=accuracy_score(test_y,prediction)
print(accuracy_score)

#printing the misclassified values from prediction
print("Misclassified Samples:%d"%(test_y!=prediction).sum())

#Effect of K value on classifier
Misclassified_sample=[]
#Calculating error for k value 1 to 20
for i in range(1,20):
    knn=KNeighborsClassifier(n_neighbors=5)
    knn.fit(train_x,train_y)
    pred_i=knn.predict(test_x)
    Misclassified_sample.append((test_y!=pred_i).sum())
print(Misclassified_sample)








